{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project4_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npW80WsO6xbo"
      },
      "source": [
        "#1. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJIPtCKjO0Jv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8XiNBwzwA1c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Lr1gaM63vb"
      },
      "source": [
        "##1.1 Train/Val/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysSmTG65XX-E"
      },
      "source": [
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIz9jX-5Yuxa"
      },
      "source": [
        "img_path = '/content/drive/MyDrive/aibootcamp/section4/chest_xray/train/NORMAL/NORMAL2-IM-1442-0001.jpeg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TNpYamsXxIA"
      },
      "source": [
        "img = image.load_img(img_path,target_size=(64,64))\n",
        "print(img)\n",
        "img_arr = image.img_to_array(img)\n",
        "print(np.max(img_arr))\n",
        "print(img_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZRoiQTiax42"
      },
      "source": [
        "img2 = image.load_img(img_path,target_size=(128,128))\n",
        "print(img2)\n",
        "img_arr2 = image.img_to_array(img2)\n",
        "print(np.max(img_arr2))\n",
        "print(img_arr2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-7Uf9t132ws"
      },
      "source": [
        "# img size 정해주기\n",
        "img_width = 64\n",
        "img_height = 64\n",
        "\n",
        "# train data augmentation\n",
        "## val은 train data의 20%\n",
        "## 보통 폐 사진은 horizontal flip 하지 않으므로 쓰지 않음.\n",
        "## shear_range 사람마다 방향을 틀 수 있으니 조정\n",
        "## zoom_range 체구가 다르니 상대적 크기 조정을 통한 학습\n",
        "# 전처리 1: rescale을 통한 정규화 (0,255 > 0,1)\n",
        "# 전처리 2: ImageDataGenerator을 통한 데이터 증강\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   validation_split =0.2)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# train set 만들기\n",
        "# 전처리 3: rgb X. grayscale O\n",
        "train_path = '/content/drive/MyDrive/aibootcamp/section4/chest_xray/train'\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (img_width, img_height),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary',                                \n",
        "                                                 color_mode = 'grayscale',                                                 \n",
        "                                                 subset = 'training')\n",
        "# val set 만들기\n",
        "validation_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (img_width, img_height),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 subset= 'validation')\n",
        "# test set 만들기\n",
        "test_path = '/content/drive/MyDrive/aibootcamp/section4/chest_xray/test'\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (img_width, img_height),\n",
        "                                            batch_size = 32,\n",
        "                                            color_mode = 'grayscale',\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY9LQpOTEIw0"
      },
      "source": [
        "x = img_arr.reshape((1,) + img_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9By5SCADNMI"
      },
      "source": [
        "idx = 0\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "axs = []\n",
        "for batch in train_datagen.flow(x , batch_size=1): # 여기서 batch는 x가 됨\n",
        "    axs.append(fig.add_subplot(5, 4, idx+1))\n",
        "    axs[idx].imshow(image.array_to_img(batch[0]))\n",
        "    idx += 1\n",
        "    if idx%20 == 0:\n",
        "        break\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWEDs34XQSJs"
      },
      "source": [
        "num2 = test_set.classes\n",
        "uni2,count2 = np.unique(num2,return_counts=True)\n",
        "print(count2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpLqWzP7jJoD"
      },
      "source": [
        "num = training_set.classes\n",
        "uni, count = np.unique(num,return_counts=True)\n",
        "print(uni)\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIhSpVITlAy-"
      },
      "source": [
        "# 전처리 4: 데이터 불균형 해소\n",
        "normal_num = count[0]\n",
        "pneumonia_num = count[1]\n",
        "total = normal_num + pneumonia_num\n",
        "w0 = round((1/normal_num)*(total)/2.0,2)\n",
        "w1 = round((1/pneumonia_num)*(total)/2.0,2)\n",
        "class_weight = {0: w0, 1:w1}\n",
        "print('Normal weight: ',w0)\n",
        "print('Pneumonia weight: ',w1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IULlOJLSoNr5"
      },
      "source": [
        "# 데이터 시각화\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(train_path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "# Import Val Data\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(train_path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(25):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkzPfO7B6_gc"
      },
      "source": [
        "#2. CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZZ_ZoQP7EzR"
      },
      "source": [
        "##2.1 모델 구축"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAWYm5FH4mmd"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJMnHvK4pYz"
      },
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "model1.add(Conv2D(32, (3, 3), input_shape = (img_width, img_height, 1), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "model1.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "model1.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "model1.add(Dense(units = 128, activation = 'relu'))\n",
        "model1.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Hy54Ys7L_a"
      },
      "source": [
        "##2.2 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAfVxTjkqfol"
      },
      "source": [
        "METRICS = ['accuracy', tf.keras.metrics.Precision(name='precision'),\n",
        "           tf.keras.metrics.Recall(name='recall')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI_-4zX-4sDq"
      },
      "source": [
        "# Compiling the CNN\n",
        "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNtH7ydQ7N62"
      },
      "source": [
        "##2.3 Early Stopping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xuLJ-kqV3HU"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_acc',mode='max',verbose=1,patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWXYa3me7Rz8"
      },
      "source": [
        "##2.4 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmjsI6CLqLUJ"
      },
      "source": [
        "history = model1.fit_generator(training_set,\n",
        "                         steps_per_epoch = training_set.samples//batch_size,\n",
        "                         epochs = 20, callbacks=[es],\n",
        "                         validation_data = validation_set,\n",
        "                         validation_steps = validation_set.samples//batch_size,\n",
        "                         class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFoD0kcFxm6R"
      },
      "source": [
        "##2.5 하이퍼 파라미터 튜닝 과정 이미지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_nI8OmRy1Gl"
      },
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['recall', 'accuracy', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpBaXOg27WFn"
      },
      "source": [
        "##2.6 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5DjilY64xar"
      },
      "source": [
        "model1.evaluate(test_set,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFdt5Ed4WseM"
      },
      "source": [
        "model2.save('pneu_model2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZmXNGKIW4WF"
      },
      "source": [
        "classifier.save('pneu_model1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}